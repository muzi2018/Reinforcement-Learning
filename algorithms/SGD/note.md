| Robbins–Monro                     | SGD                                        |
| ---------------------------------- | ------------------------------------------ |
| ($w_{k+1} = w_k - \alpha_k Y_k$) | ($w_{k+1} = w_k - \eta \nabla J_i(w_k)$) |
| Y_k 是随机观测                     | ∇J_i(w) 是带噪声梯度                      |
| 求 (E[Y] = 0) 的解                 | 求 (\nabla J(w) = 0) 的解                  |
| α_k 随 k 递减                     | 学习率 η 可以固定或衰减                   |

SGD = Robbins–Monro 应用在优化问题上
